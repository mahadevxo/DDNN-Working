{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications as apps # type: ignore\n",
    "import tensorflow as tf # type: ignore\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    model.save(f\"{filename}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_pruning(w: tf.Variable, k: float) -> tf.Variable:\n",
    "    k = tf.cast(\n",
    "        tf.round(\n",
    "            tf.cast(tf.size(w), tf.float32) * k\n",
    "        ), dtype=tf.int32\n",
    "    )\n",
    "\n",
    "    w_reshaped = tf.reshape(w, [-1])\n",
    "\n",
    "    _, indices = tf.nn.top_k(\n",
    "        tf.negative(tf.abs(w_reshaped)),\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    mask = tf.tensor_scatter_nd_update(\n",
    "        tf.ones_like(w_reshaped, dtype=tf.float32),\n",
    "        tf.reshape(indices, [-1, 1]),\n",
    "        tf.zeros([k], dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "    return w.assign(tf.reshape(w_reshaped * mask, tf.shape(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_pruning(w: tf.Variable, k: float) -> tf.Variable:\n",
    "    norm = tf.norm(w, axis=0)\n",
    "\n",
    "    num_cols = tf.cast(tf.shape(w)[1], dtype=tf.float32)\n",
    "    k = tf.cast(tf.round(num_cols * k), dtype=tf.int32)\n",
    "\n",
    "    _, col_indices = tf.nn.top_k(\n",
    "        tf.negative(norm),\n",
    "        k=k,\n",
    "        sorted=True\n",
    "    )\n",
    "\n",
    "    row_indices = tf.range(tf.shape(w)[0])\n",
    "    row_indices, col_indices = tf.meshgrid(row_indices, col_indices, indexing='ij')\n",
    "\n",
    "    indices = tf.stack([tf.reshape(row_indices, [-1]), tf.reshape(col_indices, [-1])], axis=1)\n",
    "\n",
    "    # Ensure update size matches indices\n",
    "    num_updates = tf.shape(indices)[0]\n",
    "    updates = tf.zeros([num_updates], dtype=tf.float32)\n",
    "\n",
    "    return w.assign(\n",
    "        tf.tensor_scatter_nd_update(\n",
    "            w,\n",
    "            indices,\n",
    "            updates\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 00:27:17.682051: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Inner dimensions of output shape must match inner dimensions of updates shape. Output: [3,3,3,64] updates: [54]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Inner dimensions of output shape must match inner dimensions of updates shape. Output: [3,3,3,64] updates: [54] [Op:TensorScatterUpdate]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D):\n\u001b[1;32m      7\u001b[0m         layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Enable training for weight modification\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m         \u001b[43munit_pruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Re-freeze the layer after pruning\u001b[39;00m\n\u001b[1;32m     11\u001b[0m save_model(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munit_pruned_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m, in \u001b[0;36munit_pruning\u001b[0;34m(w, k)\u001b[0m\n\u001b[1;32m     19\u001b[0m num_updates \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(indices)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m updates \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros([num_updates], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m w\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_scatter_nd_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdates\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/TF-ML/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/TF-ML/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Inner dimensions of output shape must match inner dimensions of updates shape. Output: [3,3,3,64] updates: [54] [Op:TensorScatterUpdate]"
     ]
    }
   ],
   "source": [
    "model = apps.VGG16(weights='imagenet', include_top=True)\n",
    "model.trainable = False\n",
    "save_model(model, 'original_model')\n",
    "\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        layer.trainable = True  # Enable training for weight modification\n",
    "        unit_pruning(layer.kernel, 0.5)\n",
    "        layer.trainable = False  # Re-freeze the layer after pruning\n",
    "\n",
    "save_model(model, 'unit_pruned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
