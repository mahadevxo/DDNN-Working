{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2aad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from MVCNN.models import MVCNN\n",
    "from PFT import PruningFineTuner\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from torchvision import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eaa8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(model):\n",
    "    param_size = sum(\n",
    "        param.nelement() * param.element_size() for param in model.parameters()\n",
    "    )\n",
    "    buffer_size = sum(\n",
    "        buffer.nelement() * buffer.element_size() for buffer in model.buffers()\n",
    "    )\n",
    "    return (param_size + buffer_size) / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837c7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_1 size:  35.17333984375\n",
      "net_2 size:  456.54700088500977\n"
     ]
    }
   ],
   "source": [
    "model = MVCNN.SVCNN('SVCNN')\n",
    "model.load_state_dict(torch.load('model-00030.pth', map_location='mps'))\n",
    "\n",
    "print(\"net_1 size: \", get_size(model.net_1))\n",
    "print(\"net_2 size: \", get_size(model.net_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e90d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Count the total number of parameters in the model with detailed breakdown.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        \n",
    "    Returns:\n",
    "        total_params: Total number of parameters\n",
    "        trainable_params: Number of trainable parameters\n",
    "        non_trainable_params: Number of frozen parameters\n",
    "        size_mb: Model size in MB\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    \n",
    "    # Calculate model size in MB\n",
    "    size_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    size_mb = size_bytes / (1024 * 1024)\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Non-trainable parameters: {non_trainable_params:,}\")\n",
    "    print(f\"Model size: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Optional: Show breakdown by layer\n",
    "    print(\"\\nParameter breakdown by layer:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: {param.numel():,} parameters\")\n",
    "        \n",
    "    return total_params, trainable_params, non_trainable_params, size_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae38e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 9,220,480\n",
      "Trainable parameters: 9,220,480\n",
      "Non-trainable parameters: 0\n",
      "Model size: 35.17 MB\n",
      "\n",
      "Parameter breakdown by layer:\n",
      "0.weight: 1,728 parameters\n",
      "0.bias: 64 parameters\n",
      "3.weight: 73,728 parameters\n",
      "3.bias: 128 parameters\n",
      "6.weight: 294,912 parameters\n",
      "6.bias: 256 parameters\n",
      "8.weight: 589,824 parameters\n",
      "8.bias: 256 parameters\n",
      "11.weight: 1,179,648 parameters\n",
      "11.bias: 512 parameters\n",
      "13.weight: 2,359,296 parameters\n",
      "13.bias: 512 parameters\n",
      "16.weight: 2,359,296 parameters\n",
      "16.bias: 512 parameters\n",
      "18.weight: 2,359,296 parameters\n",
      "18.bias: 512 parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9220480, 9220480, 0, 35.17333984375)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model.net_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca6da931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 119,681,057\n",
      "Trainable parameters: 119,681,057\n",
      "Non-trainable parameters: 0\n",
      "Model size: 456.55 MB\n",
      "\n",
      "Parameter breakdown by layer:\n",
      "0.weight: 102,760,448 parameters\n",
      "0.bias: 4,096 parameters\n",
      "3.weight: 16,777,216 parameters\n",
      "3.bias: 4,096 parameters\n",
      "6.weight: 135,168 parameters\n",
      "6.bias: 33 parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(119681057, 119681057, 0, 456.54700088500977)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model.net_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "341eab14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 102,764,544\n",
      "Trainable parameters: 102,764,544\n",
      "Non-trainable parameters: 0\n",
      "Model size: 392.02 MB\n",
      "\n",
      "Parameter breakdown by layer:\n",
      "weight: 102,760,448 parameters\n",
      "bias: 4,096 parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(102764544, 102764544, 0, 392.015625)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model.net_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9c37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = MVCNN.SVCNN('SVCNN')\n",
    "    model.load_state_dict(torch.load('mvcnn.pth', map_location='mps'))\n",
    "    model = deepcopy(model)\n",
    "        \n",
    "    print(f\"Model size: {get_size(model):.2f} MB\")\n",
    "    \n",
    "    # x, y = model.net_1, model.net_2\n",
    "    # del model.net_1\n",
    "    # del model.net_2\n",
    "    \n",
    "    # model.features = x\n",
    "    # model.classifier = y\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229dccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(pruning_amount, size):\n",
    "    if 'results_again.csv' not in os.listdir():\n",
    "        with open('results_again.csv', 'w') as f:\n",
    "            f.write(\"Pruning Amount, Model Size\\n\")\n",
    "    with open('results_again.csv', 'a') as f:\n",
    "        f.write(f\"{pruning_amount}, {size}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2a0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_model():\n",
    "    model = models.vgg11(weights=models.VGG11_Weights.IMAGENET1K_V1)\n",
    "    x, y, z = model.avgpool, model.classifier, model.features\n",
    "\n",
    "    model.avgpool = None\n",
    "    model.classifier = None\n",
    "    model.features = None\n",
    "\n",
    "    del model.classifier\n",
    "    del model.features\n",
    "    del model.avgpool\n",
    "\n",
    "    model.net_1 = z\n",
    "    model.avgpool = x\n",
    "    model.net_2 = y\n",
    "    model.net_2[6] = torch.nn.Linear(4096, 33)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16fc60ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruner = PruningFineTuner(get_vgg_model())\n",
    "# pruning_amount = 48\n",
    "\n",
    "# model = pruner.prune(pruning_amount)\n",
    "# print(f\"Model size after pruning: {get_size(model):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38f59354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 491.72 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVCNN(\n",
       "  (net_1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (net_2): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=33, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d1e4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your original pruning amounts\n",
    "pruning_amounts = np.arange(0, 100, 4)\n",
    "\n",
    "# Center value\n",
    "center = np.mean(pruning_amounts)\n",
    "\n",
    "# Compute Gaussian-based probabilities\n",
    "sigma = 15  # controls how \"tight\" around center you prefer; adjust if needed\n",
    "probabilities = np.exp(-0.5 * ((pruning_amounts - center) / sigma) ** 2)\n",
    "probabilities /= probabilities.sum()  # normalize to sum to 1\n",
    "\n",
    "# Sample without replacement according to the probabilities\n",
    "shuffled_pruning_amounts = np.random.choice(pruning_amounts, size=len(pruning_amounts), replace=False, p=probabilities)\n",
    "\n",
    "# Now shuffled_pruning_amounts starts more around the middle\n",
    "pruning_amounts = shuffled_pruning_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceff1125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 28, 44, 48, 76, 52, 16, 80, 20, 56, 40, 64, 72, 32, 68, 24, 60,\n",
       "       88, 84,  4, 12, 96,  8, 92,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruning_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e82497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning amounts: [36 28 44 48 76 52 16 80 20 56 40 64 72 32 68 24 60 88 84  4 12 96  8 92\n",
      "  0]\n",
      "Model size: 491.72 MB\n",
      "Total Filters to prune: 990 For Pruning Percentage: 36\n",
      "Layers that will be pruned {0: 17, 6: 78, 16: 178, 13: 209, 18: 190, 11: 204, 8: 96, 3: 18}\n",
      "Pruning Filters\n",
      "Total Filters Pruned: 990\n",
      "Model size after 36% pruning: 324.98 MB\n",
      "PruningFineTuner object deleted and memory cleared.\n",
      "Model size: 491.72 MB\n",
      "Total Filters to prune: 770 For Pruning Percentage: 28\n",
      "Layers that will be pruned {16: 153, 6: 79, 18: 158, 11: 149, 8: 69, 13: 138, 0: 11, 3: 13}\n",
      "Pruning Filters\n",
      "Total Filters Pruned: 770\n",
      "Model size after 28% pruning: 353.60 MB\n",
      "PruningFineTuner object deleted and memory cleared.\n",
      "Model size: 491.72 MB\n",
      "Total Filters to prune: 1210 For Pruning Percentage: 44\n",
      "Layers that will be pruned {0: 24, 11: 263, 18: 221, 8: 112, 6: 110, 16: 213, 13: 239, 3: 28}\n",
      "Pruning Filters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x108533a10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/ML/lib/python3.13/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f\"Pruning amounts: {pruning_amounts}\")\n",
    "for pruning_amount in pruning_amounts:\n",
    "    pruner = PruningFineTuner(get_model())\n",
    "    model = pruner.prune(pruning_amount, True)\n",
    "    print(f\"Model size after {pruning_amount}% pruning: {get_size(model):.2f} MB\")\n",
    "    write_to_file(pruning_amount, get_size(model))\n",
    "    pruner.reset()\n",
    "    del model\n",
    "    del pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6c54390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_pruning_amounts(start, end, step):\n",
    "        pruning_amounts = np.arange(start, end, step)\n",
    "        center = np.mean(pruning_amounts)\n",
    "\n",
    "        sigma = 15  # controls how \"tight\" around center you prefer; adjust if needed\n",
    "        probabilities = np.exp(-0.5 * ((pruning_amounts - center) / sigma) ** 2)\n",
    "        probabilities /= probabilities.sum()  # normalize to sum to 1\n",
    "\n",
    "        pruning_amounts = np.random.choice(\n",
    "            pruning_amounts,\n",
    "            size=len(pruning_amounts),\n",
    "            replace=False,\n",
    "            p=probabilities,\n",
    "        )\n",
    "\n",
    "        done = [80, 43, 58, 41, 66, 17, 61, 60, 27, 34, 50, 26, 29, 81, 52]\n",
    "        print(f\"Done pruning amounts: {len(done)}\")\n",
    "\n",
    "        # Filter out the done pruning amounts\n",
    "        pruning_amounts = [amount for amount in pruning_amounts if amount not in done]\n",
    "        print(f\"Remaining pruning amounts: {len(pruning_amounts)}\")\n",
    "        \n",
    "        print(f\"Percentage Done: {len(done) / len(pruning_amounts) * 100:.2f}%\")\n",
    "        \n",
    "        return pruning_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6fe131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done pruning amounts: 15\n",
      "Remaining pruning amounts: 85\n",
      "Percentage Done: 17.65%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.int64(44),\n",
       " np.int64(51),\n",
       " np.int64(38),\n",
       " np.int64(45),\n",
       " np.int64(69),\n",
       " np.int64(40),\n",
       " np.int64(39),\n",
       " np.int64(64),\n",
       " np.int64(49),\n",
       " np.int64(54),\n",
       " np.int64(56),\n",
       " np.int64(48),\n",
       " np.int64(46),\n",
       " np.int64(32),\n",
       " np.int64(35),\n",
       " np.int64(57),\n",
       " np.int64(36),\n",
       " np.int64(76),\n",
       " np.int64(28),\n",
       " np.int64(70),\n",
       " np.int64(24),\n",
       " np.int64(37),\n",
       " np.int64(93),\n",
       " np.int64(53),\n",
       " np.int64(65),\n",
       " np.int64(47),\n",
       " np.int64(83),\n",
       " np.int64(67),\n",
       " np.int64(55),\n",
       " np.int64(62),\n",
       " np.int64(73),\n",
       " np.int64(23),\n",
       " np.int64(25),\n",
       " np.int64(42),\n",
       " np.int64(22),\n",
       " np.int64(63),\n",
       " np.int64(33),\n",
       " np.int64(68),\n",
       " np.int64(14),\n",
       " np.int64(59),\n",
       " np.int64(72),\n",
       " np.int64(15),\n",
       " np.int64(71),\n",
       " np.int64(31),\n",
       " np.int64(74),\n",
       " np.int64(30),\n",
       " np.int64(75),\n",
       " np.int64(90),\n",
       " np.int64(79),\n",
       " np.int64(19),\n",
       " np.int64(12),\n",
       " np.int64(8),\n",
       " np.int64(21),\n",
       " np.int64(18),\n",
       " np.int64(11),\n",
       " np.int64(77),\n",
       " np.int64(78),\n",
       " np.int64(16),\n",
       " np.int64(87),\n",
       " np.int64(13),\n",
       " np.int64(86),\n",
       " np.int64(82),\n",
       " np.int64(84),\n",
       " np.int64(20),\n",
       " np.int64(92),\n",
       " np.int64(89),\n",
       " np.int64(88),\n",
       " np.int64(10),\n",
       " np.int64(9),\n",
       " np.int64(6),\n",
       " np.int64(7),\n",
       " np.int64(4),\n",
       " np.int64(99),\n",
       " np.int64(85),\n",
       " np.int64(97),\n",
       " np.int64(3),\n",
       " np.int64(5),\n",
       " np.int64(1),\n",
       " np.int64(94),\n",
       " np.int64(91),\n",
       " np.int64(2),\n",
       " np.int64(96),\n",
       " np.int64(0),\n",
       " np.int64(95),\n",
       " np.int64(98)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_pruning_amounts(0, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8bf13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abcddf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
