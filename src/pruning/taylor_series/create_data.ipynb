{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a61596cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b71540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pruning_data(pruning_amounts, pre_accuracy, post_accuracy, comp_time, model_size, step=1, window_size=7, poly_order=6, noise=1.0):\n",
    "    df = pd.DataFrame({'pruning': pruning_amounts, 'pre_accuracy': pre_accuracy,'accuracy': post_accuracy, 'comp_time': comp_time, 'model_size': model_size})\n",
    "    \n",
    "    new_pruning_amounts = np.arange(0, np.max(pruning_amounts) + step, step)\n",
    "    df_interp = df.set_index('pruning').reindex(new_pruning_amounts).interpolate(method='linear')\n",
    "    \n",
    "    # Apply Savitzky-Golay filter for smoothing\n",
    "    def smooth_series(series):\n",
    "        return savgol_filter(series, window_size, poly_order, mode='nearest') if len(series) > window_size else series\n",
    "    \n",
    "    df_interp['pre_accuracy_smooth'] = smooth_series(df_interp['pre_accuracy'].values)\n",
    "    df_interp['post_accuracy_smooth'] = smooth_series(df_interp['accuracy'].values)\n",
    "    df_interp['comp_time_smooth'] = smooth_series(df_interp['comp_time'].values)\n",
    "    df_interp['model_size_smooth'] = smooth_series(df_interp['model_size'].values)\n",
    "    \n",
    "    # Add noise if specified\n",
    "    if noise != 0.0:\n",
    "        new_pre_acc = smooth_series(df_interp['pre_accuracy_smooth'].values) + np.random.logistic(scale=noise, size=len(df_interp))\n",
    "        new_post_acc = smooth_series(df_interp['post_accuracy_smooth'].values) + np.random.logistic(scale=noise, size=len(df_interp))\n",
    "        new_comp_time = smooth_series(df_interp['comp_time_smooth'].values) + np.random.logistic(scale=noise, size=len(df_interp))\n",
    "        new_model_size = smooth_series(df_interp['model_size_smooth'].values) + np.random.logistic(scale=noise, size=len(df_interp))\n",
    "        return new_pruning_amounts, new_pre_acc, new_post_acc, new_comp_time, new_model_size\n",
    "    else:\n",
    "        return new_pruning_amounts, df_interp['pre_accuracy_smooth'].values, df_interp['post_accuracy_smooth'].values, df_interp['comp_time_smooth'].values, df_interp['model_size_smooth'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "776b0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_amounts = []\n",
    "pre_accuracies = []\n",
    "post_accuracies = []\n",
    "comp_time = []\n",
    "model_size = []\n",
    "with open('Sheet 1-VGG16_results.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        pruning_amounts.append(float(row[0]))\n",
    "        pre_accuracies.append(float(row[2]))\n",
    "        post_accuracies.append(float(row[4]))\n",
    "        comp_time.append(float(row[5]))\n",
    "        model_size.append(float(row[6]))\n",
    "pruning_amounts = np.array(pruning_amounts)\n",
    "pre_accuracies = np.array(pre_accuracies)\n",
    "post_accuracies = np.array(post_accuracies)\n",
    "comp_time = np.array(comp_time)\n",
    "model_size = np.array(model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6588b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pruning_amounts, new_pre_acc, new_post_acc, new_comp_time, new_model_size = add_pruning_data(pruning_amounts, pre_accuracies, post_accuracies, comp_time, model_size, step=1, window_size=7, poly_order=6, noise=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8697e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(new_pruning_amounts, new_pre_acc, new_post_acc, new_comp_time, new_model_size):\n",
    "    with open('Sheet 1-VGG16_results_interpolated.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['pruning', 'pre_accuracy', 'post_accuracy', 'comp_time', 'model_size'])\n",
    "        for i in range(len(new_pruning_amounts)):\n",
    "            writer.writerow([new_pruning_amounts[i], new_pre_acc[i], new_post_acc[i], new_comp_time[i], new_model_size[i]])\n",
    "save_to_csv(new_pruning_amounts, new_pre_acc, new_post_acc, new_comp_time, new_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d07b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
