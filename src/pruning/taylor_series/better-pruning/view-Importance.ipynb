{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "823d24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "# add path\n",
    "import sys\n",
    "sys.path.append('../../../MVCNN')\n",
    "from models import MVCNN\n",
    "from tools import ImgDataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94caf73e",
   "metadata": {},
   "source": [
    "# Calculating Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174039e",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdbd4190",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2921957f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVCNN(\n",
       "  (net_1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (net_2): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=33, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MVCNN.SVCNN('mvcnn')\n",
    "weights = torch.load('../../../MVCNN/MVCNN/model-mvcnn-00050.pth', map_location=device)\n",
    "model.load_state_dict(weights)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd234112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract CNN feature extractor from the model\n",
    "feature_extractor = model.net_1\n",
    "classifier = model.net_2\n",
    "\n",
    "feature_extractor.eval()\n",
    "classifier.eval()\n",
    "\n",
    "num_views = 12  # Number of views per model\n",
    "num_classes = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895be02c",
   "metadata": {},
   "source": [
    "## Accuracy Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c348a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global or at top of script\n",
    "view_order = [0, 1, 10, 11, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d12fb86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(\n",
    "    model: torch.nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    num_classes: int,\n",
    "    device: torch.device,\n",
    "    single_view: bool = False,\n",
    "    view_idx: int = 0,\n",
    "    drop_view_label: Optional[int] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    - single_view: evaluate on only loader batch[:, view_idx]\n",
    "    - drop_view_label: the *label* of the view to drop (e.g. 5 → slice_idx 7)\n",
    "                       if None, no views are dropped.\n",
    "    \"\"\"\n",
    "\n",
    "    # map from semantic label → tensor‐slice index\n",
    "    if drop_view_label is not None:\n",
    "        assert drop_view_label in view_order, f\"{drop_view_label=} not in view_order\"\n",
    "        drop_slice = view_order.index(drop_view_label)\n",
    "    else:\n",
    "        drop_slice = None\n",
    "\n",
    "    model.eval()\n",
    "    total_correct = total_samples = 0\n",
    "    total_loss = 0.0\n",
    "    wrong_per_class = np.zeros(num_classes, dtype=int)\n",
    "    samples_per_class = np.zeros(num_classes, dtype=int)\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Validating\", unit=\"batch\", leave=False, dynamic_ncols=True)\n",
    "    for batch_i, data in enumerate(pbar):\n",
    "        labels = data[0].to(device)\n",
    "        views  = data[1].to(device)              # (N, 12, C, H, W)\n",
    "        N, V, C, H, W = views.shape\n",
    "\n",
    "        # drop the semantic view\n",
    "        if drop_slice is not None:\n",
    "            assert 0 <= drop_slice < V\n",
    "            keep = [i for i in range(V) if i != drop_slice]\n",
    "            views = views[:, keep]\n",
    "            V -= 1\n",
    "\n",
    "        # single-view path\n",
    "        if single_view:\n",
    "            assert 0 <= view_idx < V\n",
    "            x   = views[:, view_idx]           # (N, C, H, W)\n",
    "            tgt = labels                       # (N,)\n",
    "            with torch.no_grad():\n",
    "                out   = model(x)\n",
    "                loss  = F.cross_entropy(out, tgt).item()\n",
    "                preds = out.argmax(1)\n",
    "        # full-MVCNN path\n",
    "        else:\n",
    "            flat = views.reshape(-1, C, H, W)       # (N*V, C, H, W)\n",
    "            tgt  = labels.repeat_interleave(V, 0)   # (N*V,)\n",
    "            with torch.no_grad():\n",
    "                out   = model(flat)\n",
    "                loss  = F.cross_entropy(out, tgt).item()\n",
    "                preds = out.argmax(1).cpu().numpy() # flatten\n",
    "\n",
    "        total_loss += loss\n",
    "\n",
    "        if single_view:\n",
    "            correct_mask = (preds == tgt).cpu().numpy()\n",
    "            batch_correct = correct_mask.sum()\n",
    "            for i, ok in enumerate(correct_mask):\n",
    "                cls = tgt[i].item()\n",
    "                samples_per_class[cls] += 1\n",
    "                if not ok:\n",
    "                    wrong_per_class[cls] += 1\n",
    "        else:\n",
    "            preds = preds.reshape(N, V)    # (N, V)\n",
    "            voted = np.array([np.bincount(preds[i]).argmax() for i in range(N)])\n",
    "            gts   = labels.cpu().numpy()\n",
    "            batch_correct = (voted == gts).sum()\n",
    "            for i in range(N):\n",
    "                cls = gts[i]\n",
    "                samples_per_class[cls] += 1\n",
    "                if voted[i] != cls:\n",
    "                    wrong_per_class[cls] += 1\n",
    "\n",
    "        total_correct += batch_correct\n",
    "        total_samples += N\n",
    "\n",
    "        acc = batch_correct / N\n",
    "        avg_loss = total_loss / (batch_i + 1)\n",
    "        pbar.set_postfix(acc=f\"{acc:.4f}\", loss=f\"{avg_loss:.4f}\")\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    overall_acc = total_correct / total_samples\n",
    "    per_cls_acc = (samples_per_class - wrong_per_class) / np.maximum(samples_per_class, 1)\n",
    "    mean_cls_acc = per_cls_acc[samples_per_class > 0].mean()\n",
    "\n",
    "    drop_msg = f\", dropped view {drop_view_label}\" if drop_view_label is not None else \"\"\n",
    "    mode     = f\"single-view {view_idx}\" if single_view else \"full-mvcnn\"\n",
    "    print(f\"\\n[{mode}{drop_msg}] Overall Acc: {overall_acc:.4f}   Mean Class Acc: {mean_cls_acc:.4f}\")\n",
    "\n",
    "    return overall_acc, mean_cls_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3874bb6",
   "metadata": {},
   "source": [
    "## Dataset Initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7952a225",
   "metadata": {},
   "source": [
    "### MVCNN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f160f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_mvcnn = ImgDataset.MultiviewImgDataset(\n",
    "    root_dir='../../../MVCNN/ModelNet40-12View/*/test',\n",
    "    scale_aug=False,\n",
    "    rot_aug=False,\n",
    "    test_mode=True,\n",
    "    num_models=0,\n",
    "    num_views=12,\n",
    ")\n",
    "test_loader_mvcnn = torch.utils.data.DataLoader(\n",
    "    test_dataset_mvcnn,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8b003",
   "metadata": {},
   "source": [
    "### SVCNN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b82b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_svcnn = ImgDataset.SingleImgDataset(\n",
    "    root_dir='../../../MVCNN/ModelNet40-12View/*/test',\n",
    "    scale_aug=False,\n",
    "    rot_aug=False,\n",
    "    test_mode=True,\n",
    "    num_models=0,\n",
    ")\n",
    "test_loader_svcnn = torch.utils.data.DataLoader(\n",
    "    test_dataset_svcnn,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c69600",
   "metadata": {},
   "source": [
    "## Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64e2e9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[full-mvcnn] Overall Acc: 0.8919   Mean Class Acc: 0.8494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8919354838709678), np.float64(0.8493939393939394))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_model(model = model, loader=test_loader_mvcnn, num_classes=num_classes, device=torch.device('mps'), single_view=False, drop_view_label=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1a6da",
   "metadata": {},
   "source": [
    "## Accuracy Of Each View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67bb6a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 0] Overall Acc: 0.7505   Mean Class Acc: 0.6958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 1] Overall Acc: 0.7984   Mean Class Acc: 0.7518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 2] Overall Acc: 0.8371   Mean Class Acc: 0.7894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 3] Overall Acc: 0.8312   Mean Class Acc: 0.7764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 4] Overall Acc: 0.8000   Mean Class Acc: 0.7636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 5] Overall Acc: 0.7333   Mean Class Acc: 0.7042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 6] Overall Acc: 0.8070   Mean Class Acc: 0.7688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 7] Overall Acc: 0.8086   Mean Class Acc: 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 8] Overall Acc: 0.7844   Mean Class Acc: 0.7221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 9] Overall Acc: 0.8323   Mean Class Acc: 0.7794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 10] Overall Acc: 0.8403   Mean Class Acc: 0.7924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[single-view 11] Overall Acc: 0.8011   Mean Class Acc: 0.7776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for view_idx in range(12):\n",
    "    validate_model(\n",
    "        model=model, \n",
    "        loader=test_loader_mvcnn, \n",
    "        num_classes=num_classes, \n",
    "        device=torch.device('mps'), \n",
    "        single_view=True, \n",
    "        view_idx=view_idx, \n",
    "        drop_view_label=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deee827",
   "metadata": {},
   "source": [
    "## Accuracy While Removing Views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008acb7f",
   "metadata": {},
   "source": [
    "#### Use Multi View Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b2dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/233 [00:00<?, ?batch/s]"
     ]
    }
   ],
   "source": [
    "for view_idx in range(12):\n",
    "    validate_model(\n",
    "        model=model, \n",
    "        loader=test_loader_mvcnn, \n",
    "        num_classes=num_classes, \n",
    "        device=torch.device('mps'), \n",
    "        single_view=False, \n",
    "        view_idx=0, \n",
    "        drop_view_label=view_idx\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6da6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
